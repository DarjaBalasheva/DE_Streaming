# DE Streaming: Эмуляция и обработка потока данных

## Описание задачи

В проекте реализован сценарий потоковой обработки данных (Streaming) с использованием Apache Kafka и Python.  
В качестве источника используется датасет: 
[Portugal Real Estate 2024 (Kaggle)](https://www.kaggle.com/datasets/luvathoms/portugal-real-estate-2024)

**Задача:**
1. Эмулировать поток данных из CSV, отправляя записи в Kafka с ограничением скорости (мной реализовано 10 сообщений/сек).
2. Организовать обработку входных данных в режиме стриминга:
   - Фильтрация:
     - цена > **50,000 евро**  
     - площадь > **20 м²**
   - Группировка по:
     - `Type` (тип недвижимости)
     - `District` (район)
   - Расчёт агрегатов:
     - средняя цена
     - средняя площадь
     - общее количество объявлений
     - средняя цена за м²
3. Обновлять агрегированные данные каждые **30 секунд**.
4. Сохранять результаты в **CSV** (возможна замена на БД или Redis).

---

## Структура проекта

```plaintext
DE_Streaming/
│
├── docker-compose.yml # запуск Kafka, Zookeeper, producer, consumer
├── Dockerfile # образ с установкой зависимостей для Python сервисов
├── producer.py # producer: читает CSV и отправляет данные в Kafka
├── consumer.py # consumer: читает Kafka, обрабатывает и сохраняет агрегаты
├── data/
│ └── portugal_listings.csv # датасет
├── result/
│ └── aggregated_results.csv # результат агрегации (создаётся в процессе)
└── README.md # описание проекта
```

## Запуск проекта

### 1. Установить зависимости
Убедитесь, что у вас установлен:
- Python 3.12
- Docker
- Docker Compose

### 2. Клонирование проекта
```bash
git clone <repo_url>
cd DE_Streaming
```

### 3. Запуск сервисов
```bash
docker compose up -d --build
```

### 6. Сохранение результатов
Результаты агрегации будут сохраняться в файл `result/aggregated_results.csv`, обновляясь каждые 30 секунд.

Структура файла:

| Type      | District | avg_price | avg_area | count | avg_price_per_m2 |
|-----------|----------|-----------|----------|-------|------------------|
| Apartment | Lisbon   | 150000    | 75       | 120   | 2000             |
| House     | Porto    | 250000    | 120      | 80    | 2083             |
| ...       | ...      | ...       | ...      | ...   | ...              |

где:
- `Type` — тип недвижимости (Apartment, House и т.д.)
- `District` — район (Lisbon, Porto и т.д.)
- `avg_price` — средняя цена
- `avg_area` — средняя площадь
- `count` — общее количество объявлений
- `avg_price_per_m2` — средняя цена за м²

### 6. Визуализация данных
С помощью Streamlit реализован дашборд для визуализации агрегированных данных по ссылке: http://localhost:8501

### 7. Остановка проект
```bash
docker compose down
```

## Технологии
Apache Kafka + Zookeeper — брокер сообщений
Python — producer, consumer и dashboard
Docker Compose — инфраструктура проекта
CSV — хранение результатов
Streamlit — визуализация